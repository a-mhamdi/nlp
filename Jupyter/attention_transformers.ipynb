{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-mhamdi/deep_learning_nlp/blob/main/03_attention_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg966paXWOH4"
      },
      "source": [
        "# Attention Mechanisms and Advanced Architectures\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT8Lvkumkemg"
      },
      "source": [
        "## Outlines\n",
        "1. [Attention mechanisms](#att-mech)\n",
        "1. [Transformer architecture basics](#transform-arch)\n",
        "1. [Self-attention](#self-att)\n",
        "1. [Multi-head attention](#multi-head-attention)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8GIXxZqWO1E"
      },
      "source": [
        "## Attention mechanisms <a name=\"att-mech\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OixXtHbHWO-D"
      },
      "source": [
        "## Transformer architecture basics <a name=\"transform-arch\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7uaFhz9WPHA"
      },
      "source": [
        "## Self-attention <a name=\"self-att\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfcPc8nKWPUu"
      },
      "source": [
        "## Multi-head attention <a name=\"multi-head-attention\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "import numpy as np\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import random\n",
        "from collections import Counter\n"
      ],
      "metadata": {
        "id": "Hs41hVpMJlhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple positional encoding"
      ],
      "metadata": {
        "id": "p1zZPYh0J5DL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0)\n",
        "\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "PdBmiTigJ79e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequence-to-sequence translation model using Transformer"
      ],
      "metadata": {
        "id": "pusQXympJ3Qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerTranslator(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, nhead, num_encoder_layers,\n",
        "                 num_decoder_layers, dim_feedforward, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Source and target embeddings\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        # Positional encoding layer\n",
        "        self.positional_encoding = PositionalEncoding(d_model)\n",
        "\n",
        "        # Transformer layers\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_encoder_layers,\n",
        "            num_decoder_layers=num_decoder_layers,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        # Final linear layer\n",
        "        self.output_layer = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "        # Initialize parameters\n",
        "        self.init_weights()\n",
        "\n",
        "        # Save model dimensions\n",
        "        self.d_model = d_model\n",
        "        self.tgt_vocab_size = tgt_vocab_size\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.src_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.tgt_embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.output_layer.bias.data.zero_()\n",
        "        self.output_layer.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def create_masks(self, src, tgt):\n",
        "        # Create padding masks\n",
        "        src_padding_mask = (src == 0).to(src.device)\n",
        "        tgt_padding_mask = (tgt == 0).to(tgt.device)\n",
        "\n",
        "        # Create causal mask for decoder (to prevent attention to future tokens)\n",
        "        tgt_seq_len = tgt.size(1)\n",
        "        tgt_mask = torch.triu(torch.ones(tgt_seq_len, tgt_seq_len), diagonal=1).bool().to(tgt.device)\n",
        "\n",
        "        return src_padding_mask, tgt_mask, tgt_padding_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # Shape of src/tgt: [batch_size, seq_len]\n",
        "\n",
        "        # Create masks\n",
        "        src_padding_mask, tgt_mask, tgt_padding_mask = self.create_masks(src, tgt)\n",
        "\n",
        "        # Embedding and positional encoding for source sequence\n",
        "        src_emb = self.src_embedding(src) * math.sqrt(self.d_model)\n",
        "        src_emb = self.positional_encoding(src_emb)\n",
        "\n",
        "        # Embedding and positional encoding for target sequence\n",
        "        tgt_emb = self.tgt_embedding(tgt) * math.sqrt(self.d_model)\n",
        "        tgt_emb = self.positional_encoding(tgt_emb)\n",
        "\n",
        "        # Transpose for PyTorch Transformer: [batch_size, seq_len, d_model] -> [seq_len, batch_size, d_model]\n",
        "        src_emb = src_emb.transpose(0, 1)\n",
        "        tgt_emb = tgt_emb.transpose(0, 1)\n",
        "\n",
        "        # Pass through transformer\n",
        "        output = self.transformer(\n",
        "            src_emb, tgt_emb,\n",
        "            tgt_mask=tgt_mask,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_key_padding_mask=tgt_padding_mask\n",
        "        )\n",
        "\n",
        "        # Transpose back: [seq_len, batch_size, d_model] -> [batch_size, seq_len, d_model]\n",
        "        output = output.transpose(0, 1)\n",
        "\n",
        "        # Pass through final linear layer\n",
        "        output = self.output_layer(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def greedy_decode(self, src, max_len, start_symbol, end_symbol):\n",
        "        \"\"\"Perform greedy decoding for inference\"\"\"\n",
        "        batch_size = src.size(0)\n",
        "        device = src.device\n",
        "\n",
        "        # Encode the source sequence\n",
        "        src_padding_mask = (src == 0).to(device)\n",
        "        src_emb = self.src_embedding(src) * math.sqrt(self.d_model)\n",
        "        src_emb = self.positional_encoding(src_emb)\n",
        "        src_emb = src_emb.transpose(0, 1)\n",
        "\n",
        "        memory = self.transformer.encoder(src_emb, src_key_padding_mask=src_padding_mask)\n",
        "\n",
        "        # Initialize target with start symbol\n",
        "        ys = torch.ones(batch_size, 1).fill_(start_symbol).long().to(device)\n",
        "\n",
        "        for i in range(max_len-1):\n",
        "            # Decode one token at a time\n",
        "            tgt_mask = torch.triu(torch.ones((i+1, i+1)), diagonal=1).bool().to(device)\n",
        "            tgt_padding_mask = (ys == 0).to(device)\n",
        "\n",
        "            tgt_emb = self.tgt_embedding(ys) * math.sqrt(self.d_model)\n",
        "            tgt_emb = self.positional_encoding(tgt_emb)\n",
        "            tgt_emb = tgt_emb.transpose(0, 1)\n",
        "\n",
        "            output = self.transformer.decoder(tgt_emb, memory, tgt_mask=tgt_mask,\n",
        "                                             tgt_key_padding_mask=tgt_padding_mask)\n",
        "            output = output.transpose(0, 1)\n",
        "            output = self.output_layer(output)\n",
        "\n",
        "            # Get next token\n",
        "            prob = output[:, -1]\n",
        "            _, next_word = torch.max(prob, dim=1)\n",
        "            next_word = next_word.unsqueeze(1)\n",
        "\n",
        "            # Concatenate with output so far\n",
        "            ys = torch.cat([ys, next_word], dim=1)\n",
        "\n",
        "            # Check if all sequences have reached the end symbol\n",
        "            if (next_word == end_symbol).all():\n",
        "                break\n",
        "\n",
        "        return ys"
      ],
      "metadata": {
        "id": "PwxfC_7KJ_DW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translation dataset"
      ],
      "metadata": {
        "id": "pYEb932oJzTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_sentences, tgt_sentences, src_vocab=None, tgt_vocab=None,\n",
        "                 max_vocab_size=10000, max_seq_length=100):\n",
        "        self.src_sentences = src_sentences\n",
        "        self.tgt_sentences = tgt_sentences\n",
        "        self.max_seq_length = max_seq_length\n",
        "\n",
        "        # Special tokens\n",
        "        self.PAD_IDX = 0\n",
        "        self.SOS_IDX = 1\n",
        "        self.EOS_IDX = 2\n",
        "        self.UNK_IDX = 3\n",
        "\n",
        "        # Build vocabularies if not provided\n",
        "        if src_vocab is None:\n",
        "            self.src_vocab = self.build_vocab(src_sentences, max_vocab_size)\n",
        "        else:\n",
        "            self.src_vocab = src_vocab\n",
        "\n",
        "        if tgt_vocab is None:\n",
        "            self.tgt_vocab = self.build_vocab(tgt_sentences, max_vocab_size)\n",
        "        else:\n",
        "            self.tgt_vocab = tgt_vocab\n",
        "\n",
        "    def build_vocab(self, sentences, max_vocab_size):\n",
        "        # Count word frequencies\n",
        "        counter = Counter()\n",
        "        for sentence in sentences:\n",
        "            counter.update(sentence.lower().split())\n",
        "\n",
        "        # Sort by frequency\n",
        "        words = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
        "        words = words[:max_vocab_size-4]  # Leave room for special tokens\n",
        "\n",
        "        # Create vocab dictionary\n",
        "        vocab = {\n",
        "            '<pad>': self.PAD_IDX,\n",
        "            '<sos>': self.SOS_IDX,\n",
        "            '<eos>': self.EOS_IDX,\n",
        "            '<unk>': self.UNK_IDX\n",
        "        }\n",
        "\n",
        "        for i, (word, _) in enumerate(words):\n",
        "            vocab[word] = i + 4\n",
        "\n",
        "        return vocab\n",
        "\n",
        "    def sentence_to_indices(self, sentence, vocab):\n",
        "        # Convert sentence to sequence of indices\n",
        "        words = sentence.lower().split()[:self.max_seq_length-2]  # Leave room for SOS/EOS\n",
        "        indices = [self.SOS_IDX]\n",
        "        indices.extend([vocab.get(word, self.UNK_IDX) for word in words])\n",
        "        indices.append(self.EOS_IDX)\n",
        "        return indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src_sentence = self.src_sentences[idx]\n",
        "        tgt_sentence = self.tgt_sentences[idx]\n",
        "\n",
        "        src_indices = self.sentence_to_indices(src_sentence, self.src_vocab)\n",
        "        tgt_indices = self.sentence_to_indices(tgt_sentence, self.tgt_vocab)\n",
        "\n",
        "        return torch.tensor(src_indices), torch.tensor(tgt_indices)\n"
      ],
      "metadata": {
        "id": "r3zNmEUlKFhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collate function for padding sequences to the same length"
      ],
      "metadata": {
        "id": "K1MgotD-Jxyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_translation_batch(batch):\n",
        "    src_sequences, tgt_sequences = zip(*batch)\n",
        "\n",
        "    # Pad sequences\n",
        "    src_padded = pad_sequence(src_sequences, batch_first=True, padding_value=0)\n",
        "    tgt_padded = pad_sequence(tgt_sequences, batch_first=True, padding_value=0)\n",
        "\n",
        "    return src_padded, tgt_padded\n"
      ],
      "metadata": {
        "id": "lgFFm18NKGut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train function"
      ],
      "metadata": {
        "id": "ho4dwpzfJwdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for src, tgt in dataloader:\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "        # For teacher forcing, use all but last token of target as input\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        # Use all but first token of target as output\n",
        "        tgt_output = tgt[:, 1:]\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(src, tgt_input)\n",
        "\n",
        "        # Reshape for loss calculation\n",
        "        output = output.reshape(-1, output.size(-1))\n",
        "        tgt_output = tgt_output.reshape(-1)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, tgt_output)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Apply gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n"
      ],
      "metadata": {
        "id": "2mF89jp3KJ7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation function"
      ],
      "metadata": {
        "id": "FgvxDgrXJu6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            src, tgt = src.to(device), tgt.to(device)\n",
        "\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            output = model(src, tgt_input)\n",
        "            output = output.reshape(-1, output.size(-1))\n",
        "            tgt_output = tgt_output.reshape(-1)\n",
        "\n",
        "            loss = criterion(output, tgt_output)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n"
      ],
      "metadata": {
        "id": "f_McBH_zKLd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Translation function"
      ],
      "metadata": {
        "id": "WpO901DdJtW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(model, src_sentence, src_vocab, tgt_vocab, max_len=50, device='cpu'):\n",
        "    model.eval()\n",
        "\n",
        "    # Convert sentence to indices\n",
        "    idx_to_tgt = {v: k for k, v in tgt_vocab.items()}\n",
        "    PAD_IDX, SOS_IDX, EOS_IDX, UNK_IDX = 0, 1, 2, 3\n",
        "\n",
        "    # Tokenize and convert to indices\n",
        "    tokenized = src_sentence.lower().split()\n",
        "    src_indices = [SOS_IDX]\n",
        "    src_indices.extend([src_vocab.get(token, UNK_IDX) for token in tokenized])\n",
        "    src_indices.append(EOS_IDX)\n",
        "\n",
        "    # Convert to tensor\n",
        "    src_tensor = torch.tensor([src_indices]).to(device)\n",
        "\n",
        "    # Generate translation\n",
        "    with torch.no_grad():\n",
        "        output_indices = model.greedy_decode(src_tensor, max_len, SOS_IDX, EOS_IDX).squeeze(0)\n",
        "\n",
        "    # Convert back to words\n",
        "    output_tokens = []\n",
        "    for idx in output_indices:\n",
        "        token = idx_to_tgt.get(idx.item(), '<unk>')\n",
        "        if token == '<eos>':\n",
        "            break\n",
        "        if token not in ['<sos>', '<pad>']:\n",
        "            output_tokens.append(token)\n",
        "\n",
        "    return ' '.join(output_tokens)\n"
      ],
      "metadata": {
        "id": "yMGbSUB4KM4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main function to run the translator"
      ],
      "metadata": {
        "id": "DZi8YGbRJrYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Example parallel corpus (English to French)\n",
        "    src_sentences = [\n",
        "        \"hello how are you\",\n",
        "        \"I am a student\",\n",
        "        \"where is the library\",\n",
        "        \"the book is on the table\",\n",
        "        \"I like to read books\"\n",
        "    ]\n",
        "\n",
        "    tgt_sentences = [\n",
        "        \"bonjour comment allez vous\",\n",
        "        \"je suis un étudiant\",\n",
        "        \"où est la bibliothèque\",\n",
        "        \"le livre est sur la table\",\n",
        "        \"j'aime lire des livres\"\n",
        "    ]\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = TranslationDataset(src_sentences, tgt_sentences)\n",
        "    train_dataloader = DataLoader(dataset, batch_size=2, collate_fn=collate_translation_batch, shuffle=True)\n",
        "\n",
        "    # Model parameters\n",
        "    src_vocab_size = len(dataset.src_vocab)\n",
        "    tgt_vocab_size = len(dataset.tgt_vocab)\n",
        "    d_model = 128\n",
        "    nhead = 4\n",
        "    num_encoder_layers = 3\n",
        "    num_decoder_layers = 3\n",
        "    dim_feedforward = 512\n",
        "    dropout = 0.1\n",
        "\n",
        "    # Device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Create model\n",
        "    model = TransformerTranslator(\n",
        "        src_vocab_size=src_vocab_size,\n",
        "        tgt_vocab_size=tgt_vocab_size,\n",
        "        d_model=d_model,\n",
        "        nhead=nhead,\n",
        "        num_encoder_layers=num_encoder_layers,\n",
        "        num_decoder_layers=num_decoder_layers,\n",
        "        dim_feedforward=dim_feedforward,\n",
        "        dropout=dropout\n",
        "    ).to(device)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # ignore padding tokens\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 100\n",
        "    print(f\"Starting training on device: {device}\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_epoch(model, train_dataloader, optimizer, criterion, device)\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}\")\n",
        "\n",
        "            # Translation example\n",
        "            test_sentence = \"I am learning to translate\"\n",
        "            translation = translate(model, test_sentence, dataset.src_vocab, dataset.tgt_vocab, device=device)\n",
        "            print(f\"Source: {test_sentence}\")\n",
        "            print(f\"Translation: {translation}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "    # Test with some examples\n",
        "    print(\"\\nFinal Translations:\")\n",
        "    test_sentences = [\n",
        "        \"hello my friend\",\n",
        "        \"I want to learn French\",\n",
        "        \"the cat is black\"\n",
        "    ]\n",
        "\n",
        "    for sentence in test_sentences:\n",
        "        translation = translate(model, sentence, dataset.src_vocab, dataset.tgt_vocab, device=device)\n",
        "        print(f\"Source: {sentence}\")\n",
        "        print(f\"Translation: {translation}\")\n",
        "        print(\"-\" * 30)\n"
      ],
      "metadata": {
        "id": "6buWvpQbKOCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "8IzXCZdtJnX5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}