{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-mhamdi/nlp/blob/main/Jupyter/02_sequence_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLCT9OimVn2h"
      },
      "source": [
        "# Sequence Processing Foundations\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX1tauS5i-0i"
      },
      "source": [
        "## Outlines\n",
        "1. [Dataset loading and processing](#preprocess)\n",
        "1. [NN setup](#nn-setup)\n",
        "  1. [Recurrent neural network (RNN)](#rnn)\n",
        "  1. [Long short-term memory (LSTM) Network](#lstm)\n",
        "  1. [Gated recurrent unit (GRU)](#gru)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "RaNVnz3bANx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'portalocker==2.8.2'\n",
        "\n",
        "import portalocker"
      ],
      "metadata": {
        "collapsed": true,
        "id": "I_NVyEJYzd7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.2 torchtext==0.17\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oI2EB8zXkTSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for GPU availability"
      ],
      "metadata": {
        "id": "Q1azeur8ojXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "ZzDRkZ4IofcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set random seed for reproducibility"
      ],
      "metadata": {
        "id": "MdtOmRY1nVlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "Ab5fUU8Xkg8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset loading and processing <a name=\"preprocess\"></a>"
      ],
      "metadata": {
        "id": "wbK_lJrth8_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load IMDB dataset"
      ],
      "metadata": {
        "id": "gOeNNbADnZK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter = IMDB(split='train')\n",
        "test_iter = IMDB(split='test')\n",
        "train_iter"
      ],
      "metadata": {
        "id": "5SMc0ma2kizp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for a, b in train_iter:\n",
        "  print(type(a))\n",
        "  break\n",
        ""
      ],
      "metadata": {
        "id": "jG9ObWy4LUtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define tokenizer"
      ],
      "metadata": {
        "id": "Uoe-2UCynbSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer('basic_english')"
      ],
      "metadata": {
        "id": "HKRCCj9NkhlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function to yield tokens"
      ],
      "metadata": {
        "id": "YWkokQcRneBG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)"
      ],
      "metadata": {
        "id": "FAZNAkrJkiMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build vocabulary"
      ],
      "metadata": {
        "id": "qduvIKlAnf8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\", \"<pad>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "metadata": {
        "id": "Kdr1-cIqkd16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text pipeline: tokenize and convert to indices"
      ],
      "metadata": {
        "id": "iRfwx2ipnU1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]"
      ],
      "metadata": {
        "id": "gykgh3ZMkfZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pipeline(\"This is a test.\")"
      ],
      "metadata": {
        "id": "IXr-jn3GG2Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[ vocab[token] for token in tokenizer(\"this\") ]\n",
        "vocab[\"<unk>\"]"
      ],
      "metadata": {
        "id": "S6n5tpeQG8bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label pipeline: convert label to integer"
      ],
      "metadata": {
        "id": "xdg9NmPmnUER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_pipeline = lambda x: 1 if x == \"pos\" else 0"
      ],
      "metadata": {
        "id": "5vhzSAkFlDdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collate function for DataLoader"
      ],
      "metadata": {
        "id": "N-cGOFBhnSkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, lengths = [], [], []\n",
        "    for _label, _text in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        lengths.append(processed_text.size(0))\n",
        "\n",
        "    labels = torch.tensor(label_list, dtype=torch.int64)\n",
        "    padded_text = pad_sequence(text_list, batch_first=True, padding_value=vocab[\"<pad>\"])\n",
        "    lengths = torch.tensor(lengths)\n",
        "\n",
        "    return padded_text, labels, lengths"
      ],
      "metadata": {
        "id": "TvlLDdD9ktdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create DataLoader"
      ],
      "metadata": {
        "id": "hzWdZzpznQSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_iter = IMDB(split='train')\n",
        "train_dataloader = DataLoader(list(train_iter), batch_size=batch_size,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "test_iter = IMDB(split='test')\n",
        "test_dataloader = DataLoader(list(test_iter), batch_size=batch_size,\n",
        "                            collate_fn=collate_batch)"
      ],
      "metadata": {
        "id": "HRtqS4Gdkc_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NN setup <a name=\"nn-setup\"></a>"
      ],
      "metadata": {
        "id": "lOlD-wBvDENU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define model parameters"
      ],
      "metadata": {
        "id": "AM1Mg22ZnOWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 2"
      ],
      "metadata": {
        "id": "uRSySlYhkbae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE"
      ],
      "metadata": {
        "id": "_g1HGlrmH3wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training function"
      ],
      "metadata": {
        "id": "2zfmNJGhnMHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    for text, labels, _ in dataloader:\n",
        "        text, labels = text.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text)\n",
        "\n",
        "        loss = criterion(predictions, labels)\n",
        "        acc = ((predictions.argmax(1) == labels).float().sum())/len(labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss/len(dataloader), epoch_acc/len(dataloader)"
      ],
      "metadata": {
        "id": "mWOJs20-kaWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation function"
      ],
      "metadata": {
        "id": "NvniAMxenJp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for text, labels, _ in dataloader:\n",
        "            text, labels = text.to(device), labels.to(device)\n",
        "\n",
        "            predictions = model(text)\n",
        "\n",
        "            loss = criterion(predictions, labels)\n",
        "            acc = ((predictions.argmax(1) == labels).float().sum()) / len(labels)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(dataloader), epoch_acc / len(dataloader)"
      ],
      "metadata": {
        "id": "oTp0w4xNkYeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict function for a single text input"
      ],
      "metadata": {
        "id": "e4NtxWSMnFQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(model, text):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        text_tensor = torch.tensor(text_pipeline(text)).unsqueeze(0).to(device)\n",
        "        prediction = model(text_tensor)\n",
        "        return prediction.argmax(1).item()"
      ],
      "metadata": {
        "id": "WrtP3wclkXbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzfLft7sVwD_"
      },
      "source": [
        "### Recurrent neural network (RNN) <a name=\"rnn\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our designed RNN model contains:\n",
        "\n",
        "1. Embedding layer (vocab_size → embedding_dim)\n",
        "1. RNN layer with basic hidden state\n",
        "1. Dropout layer (dropout=0.5)\n",
        "1. Fully connected layer (hidden_dim → output_dim)"
      ],
      "metadata": {
        "id": "MYkZij5J7Uz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text shape: [batch_size, seq_len]\n",
        "        embedded = self.embedding(text)  # [batch_size, seq_len, embedding_dim]\n",
        "        output, hidden = self.rnn(embedded)  # output: [batch_size, seq_len, hidden_dim]\n",
        "                                            # hidden: [1, batch_size, hidden_dim]\n",
        "        hidden = hidden.squeeze(0)  # [batch_size, hidden_dim]\n",
        "        hidden = self.dropout(hidden)\n",
        "        return self.fc(hidden)  # [batch_size, output_dim]\n"
      ],
      "metadata": {
        "id": "OnbYyiNUkcOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize model, loss function, and optimizer"
      ],
      "metadata": {
        "id": "b9nT56RdpFC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_rnn = RNNModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_rnn.parameters(), lr=0.001)\n",
        "model_rnn = model_rnn.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "n1TbUINFmll3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training loop"
      ],
      "metadata": {
        "id": "9zSTZ5cUpBRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train(model_rnn, train_dataloader, optimizer, criterion)\n",
        "    test_loss, test_acc = evaluate(model_rnn, test_dataloader, criterion)\n",
        "\n",
        "    print(f'Epoch: {epoch+1}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "C26WXuX2kVjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example prediction"
      ],
      "metadata": {
        "id": "diNox4TPo_gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"This movie is amazing! I really enjoyed it.\"\n",
        "sentiment = predict_sentiment(model_rnn, sample_text)\n",
        "print(f'Sample text: \"{sample_text}\"')\n",
        "print(f'Sentiment: {\"Positive\" if sentiment == 1 else \"Negative\"}')"
      ],
      "metadata": {
        "id": "yBcS1zz3moRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text, labels, lengths in train_dataloader:\n",
        "    print(text[0])\n",
        "    print(labels[0])\n",
        "    break"
      ],
      "metadata": {
        "id": "U-NFXJD6Kcq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6oj_IKsVwLj"
      },
      "source": [
        "### Long short-term memory (LSTM) Network <a name=\"lstm\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our designed LSTM model contains:\n",
        "\n",
        "1. Embedding layer (vocab_size → embedding_dim)\n",
        "1. LSTM layer with forget, input, cell, and output gates\n",
        "1. Optional bidirectional processing\n",
        "1. Dropout layer (dropout=0.5)\n",
        "1. Fully connected layer (hidden_dim → output_dim)"
      ],
      "metadata": {
        "id": "Ke_f1FRL7wse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=1, bidirectional=False, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                           hidden_dim,\n",
        "                           num_layers=n_layers,\n",
        "                           bidirectional=bidirectional,\n",
        "                           batch_first=True,\n",
        "                           dropout=dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # If bidirectional, we need to multiply hidden_dim by 2\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text shape: [batch_size, seq_len]\n",
        "        embedded = self.embedding(text)  # [batch_size, seq_len, embedding_dim]\n",
        "\n",
        "        # LSTM returns: output, (hidden, cell)\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "\n",
        "        # If bidirectional, concat the final forward and backward hidden states\n",
        "        if self.lstm.bidirectional:\n",
        "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "        else:\n",
        "            hidden = hidden[-1,:,:]\n",
        "\n",
        "        hidden = self.dropout(hidden)\n",
        "        return self.fc(hidden)  # [batch_size, output_dim]"
      ],
      "metadata": {
        "id": "Ovimqm4YlHTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize model, loss function, and optimizer"
      ],
      "metadata": {
        "id": "UuTh7w6UorKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = LSTMModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_lstm.parameters(), lr=0.001)\n",
        "model_lstm = model_lstm.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "1lBRU-xAmkjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training loop"
      ],
      "metadata": {
        "id": "EwpDzuA8owYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train(model_lstm, train_dataloader, optimizer, criterion)\n",
        "    test_loss, test_acc = evaluate(model_lstm, test_dataloader, criterion)\n",
        "\n",
        "    print(f'Epoch: {epoch+1}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "zeoIkOUYlUr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example prediction"
      ],
      "metadata": {
        "id": "lwahminLou1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"This movie was fantastic! I really enjoyed it.\"\n",
        "sentiment = predict_sentiment(model_lstm, sample_text)\n",
        "print(f'Sample text: \"{sample_text}\"')\n",
        "print(f'Sentiment: {\"Positive\" if sentiment == 1 else \"Negative\"}')"
      ],
      "metadata": {
        "id": "n9PoOVphmqXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWou2XNqVwOR"
      },
      "source": [
        "### Gated recurrent unit (GRU) <a name=\"gru\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our designed GRU model contains:\n",
        "\n",
        "1. Embedding layer (vocab_size → embedding_dim)\n",
        "1. GRU layer with reset gate, update gate, and hidden state\n",
        "1. Optional bidirectional processing\n",
        "1. Dropout layer (dropout=0.5)\n",
        "1. Fully connected layer (hidden_dim → output_dim)"
      ],
      "metadata": {
        "id": "AaXYvkvG70Ob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers=1, bidirectional=False, dropout=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers=n_layers,\n",
        "                          bidirectional=bidirectional,\n",
        "                          batch_first=True,\n",
        "                          dropout=dropout if n_layers > 1 else 0)\n",
        "\n",
        "        # If bidirectional, multiply hidden_dim by 2\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text shape: [batch_size, seq_len]\n",
        "        embedded = self.embedding(text)  # [batch_size, seq_len, embedding_dim]\n",
        "\n",
        "        # GRU returns: output, hidden\n",
        "        output, hidden = self.gru(embedded)\n",
        "\n",
        "        # If bidirectional, concat the final forward and backward hidden states\n",
        "        if self.gru.bidirectional:\n",
        "            hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
        "        else:\n",
        "            hidden = hidden[-1,:,:]\n",
        "\n",
        "        hidden = self.dropout(hidden)\n",
        "        return self.fc(hidden)  # [batch_size, output_dim]"
      ],
      "metadata": {
        "id": "M9wMzVgLlVwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### Initialize model, loss function, and optimizer"
      ],
      "metadata": {
        "id": "jViZODeIozB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru = GRUModel(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_gru.parameters(), lr=0.001)\n",
        "model_gru = model_gru.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "byJs3pSpmWWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training loop"
      ],
      "metadata": {
        "id": "C0oxHH-No2ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train(model_gru, train_dataloader, optimizer, criterion)\n",
        "    test_loss, test_acc = evaluate(model_gru, test_dataloader, criterion)\n",
        "\n",
        "    print(f'Epoch: {epoch+1}')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "metadata": {
        "id": "nV4ecyZDlWaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example prediction"
      ],
      "metadata": {
        "id": "rcs82a8ko5HE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = \"This movie was fantastic! I really enjoyed it.\"\n",
        "sentiment = predict_sentiment(model_gru, sample_text)\n",
        "print(f'Sample text: \"{sample_text}\"')\n",
        "print(f'Sentiment: {\"Positive\" if sentiment == 1 else \"Negative\"}')"
      ],
      "metadata": {
        "id": "w-8m-63lmrpA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}